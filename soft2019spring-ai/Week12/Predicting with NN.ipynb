{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "* Training NN\n",
    "* Predicting with NN\n",
    "* Recurrent NN (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Working with MNIST\n",
    "\n",
    "MNIST(Modified National Institute of Standards and Technology database) is a database of hand-written numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.datasets\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1ffe7452b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[15], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Working with image data\n",
    "\n",
    "Images as greyscale values: 0 - 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "        90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Predicting image classes with decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have to flatten the data for our classifier\n",
    "x_train_flat = x_train.reshape(-1, 28 * 28)\n",
    "x_train_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x_test_flat = x_test.reshape(-1, 28 * 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(x_train_flat, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bf894e5d81cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \"\"\"\n\u001b[0;32m--> 576\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseSVC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobA_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobB_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvm_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             cache_size=self.cache_size)\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sparse_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, model.predict(x_test_flat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Predicting image classes with SVMs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jens/.virtualenvs/ml/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC()\n",
    "model.fit(x_train_flat[:1000], y_train[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1028"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, model.predict(x_test_flat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neural network prediction\n",
    "\n",
    "![](nn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Predicting image classes with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jens/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/jens/.virtualenvs/ml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential([\n",
    "  layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jens/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 7.8103 - acc: 0.5129\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 6.5185 - acc: 0.5944\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 6.2101 - acc: 0.6138\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 6.2615 - acc: 0.6106\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 6.0225 - acc: 0.6257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f33191ee6d8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_flat, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 20us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.4571653129577635, 0.5986]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_flat, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How neural networks are trained\n",
    "\n",
    "We know we have an activation function $f$:\n",
    "\n",
    "$$f(x) = {1 \\over {1 + e^{-x}}}$$\n",
    "\n",
    "Where the output ($o_j$) of each neuron in a layer ($l$) is defined as:\n",
    "\n",
    "$$o(x_j) = \\sum^N_{k=1} W_{kj} x_k + \\beta$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The activation function has an easy derivative:\n",
    "\n",
    "$$f'(x) = ({1 \\over {1 + e^{-x}}})' = f(x)(1 - f(x))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What are we optimising?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A loss function!\n",
    "\n",
    "$$E = {1 \\over 2} (y - \\hat{y})^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ergo, we want to know the *gradient* of the loss function, so we can find the minimum!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Differentiating the loss function\n",
    "\n",
    "$$E' = ({1 \\over 2} (y - \\hat{y})^2)' = y - \\hat{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Which parameters would we like to change in the network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$W$ and $\\beta$!\n",
    "\n",
    "* Ignore $\\beta$ for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](bp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How to differentiate with respect to $W$\n",
    "\n",
    "We are looking for this:\n",
    "$$\\Delta E = ({\\partial E \\over \\partial w_1}, {\\partial E \\over \\partial w_2}, \\dots {\\partial E \\over \\partial w_n})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$${\\partial E \\over \\partial w_{jk}} = {\\partial ((y_j - \\hat{y}_j) o_j) \\over \\partial w_{jk}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$${\\partial E \\over \\partial w_{jk}} = {\\partial E \\over \\partial o_j} {\\partial o_j \\over \\partial w_{jk}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$${\\partial E \\over \\partial w_{jk}} = \\delta_j z_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\\delta_j = o'(x_j) \\sum^N_{k=1} w_{kj} \\delta_k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](bp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Weight updates:\n",
    "\n",
    "$$\\Delta w_j = -\\gamma {\\partial E \\over \\partial w_j}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bias updates:\n",
    "\n",
    "$$\\Delta b_j = -\\gamma \\delta_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Backpropagation\n",
    "\n",
    "* Pushes errors **back** in the network, and adjusts **weights** and **biases**\n",
    "* Requires deriving the *activation function* and *error function*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](nn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Back to prediction...\n",
    "\n",
    "* We now saw that **gradient descent** is the backbone of neural network training\n",
    "* What is gradient descent vulnerable to...?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* What is the input domain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x_train_scaled = x_train_flat / 255\n",
    "x_test_scaled = x_test_flat / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential([\n",
    "  layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2928 - acc: 0.9148\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1438 - acc: 0.9565\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1078 - acc: 0.9678\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0897 - acc: 0.9724\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.0759 - acc: 0.9762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f33191ee4e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 22us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07432961855987087, 0.9769]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Running Keras / Tensorflow online\n",
    "\n",
    "* Keras is a layer on top of Tensorflow\n",
    "* Tensorflow is a library for accelerating tensor computations\n",
    "\n",
    "https://www.tensorflow.org/overview/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Catastrophic forgetting\n",
    "\n",
    "* Basic neural networks have a problem of *retaining* memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Remove all the 9's from the data\n",
    "not_nine_indices = np.where(y_train < 9)\n",
    "x_train_partial = x_train_scaled[not_nine_indices]\n",
    "y_train_partial = y_train[not_nine_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54051, 784)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_partial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54051,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_partial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Extract all the nines from the data\n",
    "nine_indices = np.where(y_train == 9)\n",
    "x_train_nines = x_train_scaled[nine_indices]\n",
    "y_train_nines = y_train[nine_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Repeat for testing data\n",
    "not_nine_indices_test = np.where(y_test < 9)\n",
    "nine_indices_test = np.where(y_test == 9)\n",
    "x_test_partial = x_test_scaled[not_nine_indices_test]\n",
    "y_test_partial = y_test[not_nine_indices_test]\n",
    "x_test_nines = x_test_scaled[nine_indices_test]\n",
    "y_test_nines = y_test[nine_indices_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential([\n",
    "  layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "54051/54051 [==============================] - 3s 47us/step - loss: 0.2544 - acc: 0.9263\n",
      "Epoch 2/5\n",
      "54051/54051 [==============================] - 3s 46us/step - loss: 0.1169 - acc: 0.9656\n",
      "Epoch 3/5\n",
      "54051/54051 [==============================] - 2s 44us/step - loss: 0.0879 - acc: 0.9732\n",
      "Epoch 4/5\n",
      "54051/54051 [==============================] - 3s 47us/step - loss: 0.0702 - acc: 0.9782\n",
      "Epoch 5/5\n",
      "54051/54051 [==============================] - 3s 49us/step - loss: 0.0586 - acc: 0.9817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f330c4dcac8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_partial, y_train_partial, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8991/8991 [==============================] - 0s 23us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05614808849002592, 0.9825380936492047]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_partial, y_test_partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "5949/5949 [==============================] - 0s 50us/step - loss: 0.4796 - acc: 0.9455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3318e24438>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_nines, y_train_nines, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1009/1009 [==============================] - 0s 21us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.536193011328492e-05, 1.0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_nines, y_test_nines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8991/8991 [==============================] - 0s 21us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10.247520637597063, 0.023690357020375672]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_partial, y_test_partial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Catastrophic forgetting\n",
    "\n",
    "* New learning completely destroys old information\n",
    "\n",
    "* Solution: introduce memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Recurrent neural networks\n",
    "\n",
    "* Recurrent neural networks contains **loops**\n",
    "\n",
    "* Each unit has a **state** $h_{l,u}$\n",
    "  * Each unit $u$ in a layer $l$ receives *two* inputs:\n",
    "    1. A vector from the previous layer\n",
    "    2. A vector from the previous *time step*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](rnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Recurrent_neural_network_unfold.svg/1920px-Recurrent_neural_network_unfold.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* We will not cover the math\n",
    "  * Just remember that **recurrent neural networks** (RNN) adds memory to the network\n",
    "  * Good at fixing the catastrophic forgetting problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## LSTM\n",
    "\n",
    "  * One type of memory is the LSTM (Long Short-Term Memory) neuron cell\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/5/53/Peephole_Long_Short-Term_Memory.svg/1920px-Peephole_Long_Short-Term_Memory.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential([\n",
    "  layers.LSTM(128, input_shape=(1, 784)),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_1_input to have 3 dimensions, but got array with shape (54051, 784)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-2b00e830f042>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_partial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_partial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected lstm_1_input to have 3 dimensions, but got array with shape (54051, 784)"
     ]
    }
   ],
   "source": [
    "model.fit(x_train_partial, y_train_partial, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Input for recurrent cells\n",
    "\n",
    "The input to every LSTM layer must be three-dimensional.\n",
    "\n",
    "The three dimensions of this input are:\n",
    "\n",
    " * Samples. One sequence is one sample. A batch is comprised of one or more samples.\n",
    " * Time Steps. One time step is one point of observation in the sample.\n",
    " * Features. One feature is one observation at a time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x_train_partial_time = x_train_partial.reshape(-1, 1, 784)\n",
    "x_test_partial_time =  x_test_partial.reshape(-1, 1, 784)\n",
    "x_train_nines_time = x_train_nines.reshape(-1, 1, 784)\n",
    "x_test_nines_time = x_test_nines.reshape(-1, 1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "54051/54051 [==============================] - 7s 135us/step - loss: 0.2346 - acc: 0.9322\n",
      "Epoch 2/5\n",
      "54051/54051 [==============================] - 7s 125us/step - loss: 0.1132 - acc: 0.9659\n",
      "Epoch 3/5\n",
      "54051/54051 [==============================] - 7s 123us/step - loss: 0.0848 - acc: 0.9743\n",
      "Epoch 4/5\n",
      "54051/54051 [==============================] - 6s 117us/step - loss: 0.0676 - acc: 0.9804\n",
      "Epoch 5/5\n",
      "54051/54051 [==============================] - 6s 117us/step - loss: 0.0570 - acc: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3318e04320>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_partial_time, y_train_partial, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8991/8991 [==============================] - 0s 43us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06756689131136447, 0.9795350905467612]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_partial_time, y_test_partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(x_train_nines_time, y_train_nines, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test_nines_time, y_test_nines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test_partial_time, y_test_partial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Using keras\n",
    "\n",
    "* Define a model of **layers**\n",
    "* Compile the model with an optimiser and a loss function\n",
    "* Train the model\n",
    "* Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "* Define a neural network using the CIFAR dataset\n",
    " * 32x32 images into 10 classes\n",
    " * Use regular `Dense` networks\n",
    "\n",
    "```python3\n",
    "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "```\n",
    "* Compile the model with the `adam` optimiser, the `sparse_categorical_crossentropy` loss function, and use the `accuracy` metric \n",
    "\n",
    "```python3\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "```\n",
    "* Fit the model with the training data\n",
    "* Evaluate it on the testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Keras visualisations\n",
    "\n",
    "https://keras.io/visualization/\n",
    "\n",
    "* Printing models\n",
    "* History graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.utils.vis_utils \n",
    "\n",
    "keras.utils.vis_utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "svg_output.create(prog='dot', format='svg'))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
